{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('capstone.db')\n",
    "# tblGame , tblMovie, tblReview, tblTVShow\n",
    "# load games dataset\n",
    "games = pd.read_sql_query(\"SELECT * FROM tblGame;\", conn)\n",
    "games['gameID'] = games.index + 1\n",
    "reviews = pd.read_sql_query(\"SELECT * FROM tblReview;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "critic_reviews = reviews[reviews['reviewType'] == 'c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daniel/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#longest review 188 words\n",
    "\n",
    "def cleaning_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'\\\\r, u', ' ', sentence)\n",
    "    sentence = re.sub(r'\\\\', \"'\", sentence)\n",
    "    sentence = sentence.split()\n",
    "    sentence = [re.sub(\"([^a-z0-9' \\t])\", '', x) for x in sentence]\n",
    "    cleaned = [s for s in sentence if s != '']\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    return cleaned\n",
    "\n",
    "                        \n",
    "critic_reviews['textClean'] = critic_reviews.apply(lambda row: cleaning_text(row['text'].encode(\"utf8\")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477672\n",
      "75.0\n",
      "19.3140135003\n",
      "106045\n",
      "96010\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEPCAYAAAAEfBBiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QAyM7Ms/j8K8aHWV4JmhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1612fe6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print len(critic_reviews)\n",
    "print critic_reviews['score'].median()\n",
    "print critic_reviews['score'].std()\n",
    "plt.hist(critic_reviews['score'], bins = 15)\n",
    "plt.xlabel('Review Scores')\n",
    "plt.ylabel('Count')\n",
    "print len(critic_reviews[critic_reviews['score'] >= (85)])\n",
    "print len(critic_reviews[critic_reviews['score'] <= (55)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daniel/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#label reviews 85 or over as positive and 55 or lower as negative\n",
    "\n",
    "def binarizer(x):\n",
    "    if x <= 55:\n",
    "        return 0\n",
    "    if x >= 85:\n",
    "        return 1\n",
    "    \n",
    "critic_reviews['overall'] = critic_reviews['score'].apply(lambda row: binarizer(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195823\n",
      "   level_0  index  gameID  movieID  tvShowID           publication  \\\n",
      "0        0      4     1.0      NaN       NaN  Digitally Downloaded   \n",
      "1        1      5     2.0      NaN       NaN         God is a Geek   \n",
      "2        2     31     2.0      NaN       NaN          PSX-Sense.nl   \n",
      "3        3     32     2.0      NaN       NaN           Push Square   \n",
      "4        4     33     2.0      NaN       NaN   We Got This Covered   \n",
      "\n",
      "                                           textClean  overall  length  \n",
      "0  it may sound like im being harsh on ginger but...      0.0      69  \n",
      "1  jojos bizarre adventure eyes in heaven feature...      1.0      21  \n",
      "2  the amount of fan service is both admirable an...      0.0      44  \n",
      "3  fun for a few bouts now and then this is a bra...      0.0      37  \n",
      "4  fans of the source material will find plenty o...      0.0      43  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    105656\n",
       "0.0     90167\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#drop rows with NA values for overall (scores between 55 and 85)\n",
    "subset = critic_reviews[pd.notnull(critic_reviews['overall'])].reset_index()\n",
    "\n",
    "length_df = subset\n",
    "length_df['length'] = pd.DataFrame(subset['textClean'].apply(lambda x: len(x.split(' '))))\n",
    "over = length_df[length_df['length'] > 2]\n",
    "#print over.sort_values('length')\n",
    "print len(over)\n",
    "\n",
    "subset = over.drop(['author', 'text', 'score', 'date', 'thumbsUp', 'thumbsDown', 'reviewType'], axis = 1).reset_index()\n",
    "print subset.head()\n",
    "subset['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100038\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#results = set()\n",
    "results = Counter()\n",
    "subset['textClean'].str.lower().str.split().apply(results.update)\n",
    "\n",
    "#number of unique words, just over 100,000\n",
    "print len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 100038\n",
    "# cut texts after this number of words \n",
    "max_length = 188\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text\n",
    "import keras \n",
    "\n",
    "tk = text.Tokenizer(max_features, filters=keras.preprocessing.text.base_filter(), split=\" \")\n",
    "tk.fit_on_texts(subset['textClean'])\n",
    "\n",
    "#create data set, both features and labels\n",
    "x = tk.texts_to_sequences(subset['textClean'])\n",
    "y = subset['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sequence.pad_sequences(x, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it's a rehash of what made sonic awesome in 1991 it's not a videogame from 2013 it controls like a game from 1991 it has gameplay like a game from 1991 warts blemishes sluggishness and all it is by all measures an astoundingly average game\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['textClean'][788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30743,  1669,   151,  1063,     8,  2550,   233,    49,   164,\n",
       "           3,     2,  1104,    62,   326,   134,   183,    23,     5,\n",
       "          80,  4333,    64,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156658 39165 156658 39165\n",
      "(156658, 188)\n",
      "(156658,)\n",
      "(39165, 188)\n",
      "(39165,)\n"
     ]
    }
   ],
   "source": [
    "print len(X_train), len(X_test), len(y_train), len(y_test)\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape\n",
    "\n",
    "#Training data shape: 121233, 203\n",
    "#Test data shape: 80822, 203\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textClean</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>to the game's credit are the tracks they're we...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>is it really that smurfin' hard to smurf up so...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>this is a solid title that gives you all kinds...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>lego star wars microfighters fails to capitali...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>a dull mashup of licences that never fires int...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>there's an embarrassment of riches for anyone ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>it all handles as you'd expect although it has...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>the alliance is the franchise's next natural s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>using vita's new graphic engine invizimals the...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>this invizimals on ps vita uses all the featur...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              textClean  overall\n",
       "2000  to the game's credit are the tracks they're we...      0.0\n",
       "2001  is it really that smurfin' hard to smurf up so...      0.0\n",
       "2002  this is a solid title that gives you all kinds...      1.0\n",
       "2003  lego star wars microfighters fails to capitali...      0.0\n",
       "2004  a dull mashup of licences that never fires int...      0.0\n",
       "2005  there's an embarrassment of riches for anyone ...      0.0\n",
       "2006  it all handles as you'd expect although it has...      0.0\n",
       "2007  the alliance is the franchise's next natural s...      1.0\n",
       "2008  using vita's new graphic engine invizimals the...      1.0\n",
       "2009  this invizimals on ps vita uses all the featur...      0.0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[['textClean', 'overall']][2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_83 (Dense)                 (None, 50)            9450        dense_input_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (None, 1)             51          dense_83[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9501\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 2s - loss: 7.3897 - acc: 0.5363 - val_loss: 7.3508 - val_acc: 0.5389\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 2s - loss: 7.4521 - acc: 0.5327 - val_loss: 7.3631 - val_acc: 0.5382\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.3758 - acc: 0.5374 - val_loss: 7.3169 - val_acc: 0.5410\n",
      "Epoch 4/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.3555 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 5/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 6/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 7/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Accuracy: 54.03%\n"
     ]
    }
   ],
   "source": [
    "#Basic Keras neural network\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = (188,)\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=256, verbose=1)\n",
    "model.fit(X_train, y_train, nb_epoch=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_85 (Dense)                 (None, 50)            9450        dense_input_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (None, 50)            2550        dense_85[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_87 (Dense)                 (None, 1)             51          dense_86[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 12051\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 3s - loss: 7.4208 - acc: 0.5344 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3553 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3553 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 4/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3553 - acc: 0.5386 - val_loss: 7.3161 - val_acc: 0.5411\n",
      "Epoch 5/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3552 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 6/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3553 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 7/30\n",
      "109660/109660 [==============================] - 4s - loss: 7.3551 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Accuracy: 54.03%\n"
     ]
    }
   ],
   "source": [
    "#Two layer Keras neural network\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = (188,)\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=256, verbose=1)\n",
    "model.fit(X_train, y_train, nb_epoch=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_88 (Dense)                 (None, 500)           94500       dense_input_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_89 (Dense)                 (None, 500)           250500      dense_88[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_90 (Dense)                 (None, 500)           250500      dense_89[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_91 (Dense)                 (None, 1)             501         dense_90[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 596001\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 67s - loss: 7.3553 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 77s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 77s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Epoch 4/30\n",
      "109660/109660 [==============================] - 78s - loss: 7.3554 - acc: 0.5386 - val_loss: 7.3162 - val_acc: 0.5411\n",
      "Accuracy: 54.03%\n"
     ]
    }
   ],
   "source": [
    "#3 layer neural network\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = (188,)\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=256, verbose=1)\n",
    "model.fit(X_train, y_train, nb_epoch=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_72 (Embedding)         (None, 188, 32)       3201888     embedding_input_67[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)             (None, 6016)          0           embedding_72[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_162 (Dense)                (None, 250)           1504250     flatten_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_163 (Dense)                (None, 1)             251         dense_162[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4706389\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 260s - loss: 0.3250 - acc: 0.8546 - val_loss: 0.2680 - val_acc: 0.8868\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 394s - loss: 0.1497 - acc: 0.9418 - val_loss: 0.3150 - val_acc: 0.8794\n",
      "Accuracy: 88.12%\n"
     ]
    }
   ],
   "source": [
    "# 1 fully connected layer with embedding layer\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_73 (Embedding)         (None, 188, 32)       3201888     embedding_input_68[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 6016)          0           embedding_73[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_164 (Dense)                (None, 250)           1504250     flatten_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_165 (Dense)                (None, 1)             251         dense_164[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4706389\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 48s - loss: 0.3535 - acc: 0.8356 - val_loss: 0.2747 - val_acc: 0.8835\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 77s - loss: 0.1852 - acc: 0.9269 - val_loss: 0.2900 - val_acc: 0.8822\n",
      "Accuracy: 88.38%\n"
     ]
    }
   ],
   "source": [
    "# 1 fully connected layer with embedding layer, with batch\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_74 (Embedding)         (None, 188, 32)       3201888     embedding_input_69[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 6016)          0           embedding_74[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_166 (Dense)                (None, 250)           1504250     flatten_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_167 (Dense)                (None, 250)           62750       dense_166[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_168 (Dense)                (None, 1)             251         dense_167[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4769139\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 73s - loss: 0.3371 - acc: 0.8450 - val_loss: 0.2663 - val_acc: 0.8889\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 130s - loss: 0.1533 - acc: 0.9409 - val_loss: 0.3138 - val_acc: 0.8780\n",
      "Accuracy: 87.62%\n"
     ]
    }
   ],
   "source": [
    "# 2 fully connected layer with embedding layer, with batch\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0\n",
    "                                      )\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_75 (Embedding)         (None, 188, 32)       3201888     embedding_input_70[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_125 (Convolution1D)(None, 188, 32)       3104        embedding_75[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_91 (MaxPooling1D)   (None, 94, 32)        0           convolution1d_125[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)             (None, 3008)          0           maxpooling1d_91[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_169 (Dense)                (None, 250)           752250      flatten_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_170 (Dense)                (None, 1)             251         dense_169[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3957493\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 185s - loss: 0.3363 - acc: 0.8472 - val_loss: 0.2560 - val_acc: 0.8928\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 182s - loss: 0.1789 - acc: 0.9294 - val_loss: 0.2743 - val_acc: 0.8921\n",
      "Accuracy: 89.07%\n"
     ]
    }
   ],
   "source": [
    "# 1 convoloutional layer and pooling layer with fully connected layer with embedding layer, with batch\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_76 (Embedding)         (None, 188, 300)      30017700    embedding_input_71[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_126 (Convolution1D)(None, 188, 64)       57664       embedding_76[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_127 (Convolution1D)(None, 188, 32)       6176        convolution1d_126[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_128 (Convolution1D)(None, 188, 16)       1552        convolution1d_127[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_92 (MaxPooling1D)   (None, 94, 16)        0           convolution1d_128[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)             (None, 1504)          0           maxpooling1d_92[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_171 (Dense)                (None, 250)           376250      flatten_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_172 (Dense)                (None, 1)             251         dense_171[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 30459593\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 746s - loss: 0.3165 - acc: 0.8579 - val_loss: 0.2448 - val_acc: 0.8986\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 957s - loss: 0.1646 - acc: 0.9352 - val_loss: 0.2648 - val_acc: 0.8966\n",
      "Accuracy: 89.46%\n"
     ]
    }
   ],
   "source": [
    "# 3 convoloutional layer and pooling layer with fully connected layer with embedding layer, with batch\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(nb_filter=64, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution1D(nb_filter=16, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_77 (Embedding)         (None, 188, 32)       3201888     embedding_input_72[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_129 (Convolution1D)(None, 188, 64)       6208        embedding_77[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 188, 64)       0           convolution1d_129[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_130 (Convolution1D)(None, 188, 32)       6176        dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 188, 32)       0           convolution1d_130[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_131 (Convolution1D)(None, 188, 16)       1552        dropout_50[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_93 (MaxPooling1D)   (None, 47, 16)        0           convolution1d_131[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)             (None, 752)           0           maxpooling1d_93[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 752)           0           flatten_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_173 (Dense)                (None, 250)           188250      dropout_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 250)           0           dense_173[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_174 (Dense)                (None, 1)             251         dropout_52[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 3404325\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 284s - loss: 0.3598 - acc: 0.8311 - val_loss: 0.2611 - val_acc: 0.8896\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 299s - loss: 0.2057 - acc: 0.9176 - val_loss: 0.2598 - val_acc: 0.8928\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 299s - loss: 0.1465 - acc: 0.9436 - val_loss: 0.2730 - val_acc: 0.8894\n",
      "Accuracy: 89.06%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "max_features = 100059\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(nb_filter=64, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution1D(nb_filter=16, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_78 (Embedding)         (None, 188, 32)       3201888     embedding_input_73[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_132 (Convolution1D)(None, 188, 16)       1552        embedding_78[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_133 (Convolution1D)(None, 188, 8)        392         convolution1d_132[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_134 (Convolution1D)(None, 188, 4)        100         convolution1d_133[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_94 (MaxPooling1D)   (None, 31, 4)         0           convolution1d_134[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                   (None, 16)            1344        maxpooling1d_94[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_175 (Dense)                (None, 250)           4250        lstm_33[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_176 (Dense)                (None, 1)             251         dense_175[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3209777\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 111s - loss: 0.4075 - acc: 0.8054 - val_loss: 0.2940 - val_acc: 0.8796\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 128s - loss: 0.2262 - acc: 0.9095 - val_loss: 0.2698 - val_acc: 0.8885\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 135s - loss: 0.1594 - acc: 0.9402 - val_loss: 0.2980 - val_acc: 0.8877\n",
      "Accuracy: 88.62%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "max_features = 100059\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 32\n",
    "ltsm_output_size=16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(nb_filter=16, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution1D(nb_filter=8, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution1D(nb_filter=4, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=6))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_79 (Embedding)         (None, 188, 200)      20011800    embedding_input_74[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 188, 200)      0           embedding_79[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_135 (Convolution1D)(None, 185, 64)       51264       dropout_53[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_95 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_135[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                   (None, 25)            9000        maxpooling1d_95[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_177 (Dense)                (None, 250)           6500        lstm_34[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_178 (Dense)                (None, 250)           62750       dense_177[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_179 (Dense)                (None, 125)           31375       dense_178[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_180 (Dense)                (None, 1)             126         dense_179[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 20172815\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 8132s - loss: 0.3305 - acc: 0.8493 - val_loss: 0.2533 - val_acc: 0.8961\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 7025s - loss: 0.1564 - acc: 0.9394 - val_loss: 0.2447 - val_acc: 0.8992\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 7232s - loss: 0.0686 - acc: 0.9756 - val_loss: 0.2990 - val_acc: 0.8934\n",
      "Accuracy: 89.41%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059\n",
    "max_length = 188\n",
    "embedding_vector_length = 200\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "kernel_size = 4\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 25\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=128, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-553329474d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m188\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mearly_stopping_monitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0membedding_vector_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "# 1-layer convolutional NN\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "max_features = 100059\n",
    "batch_size = 32\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 8\n",
    "optimizer = adam(lr=0.0001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(nb_filter=2, filter_length=2, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_49 (Embedding)         (None, 188, 100)      10005900    embedding_input_44[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 188, 100)      0           embedding_49[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_95 (Convolution1D) (None, 187, 32)       6432        dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_68 (MaxPooling1D)   (None, 93, 32)        0           convolution1d_95[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_96 (Convolution1D) (None, 90, 32)        4128        maxpooling1d_68[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_69 (MaxPooling1D)   (None, 45, 32)        0           convolution1d_96[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_97 (Convolution1D) (None, 41, 32)        5152        maxpooling1d_69[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_70 (MaxPooling1D)   (None, 20, 32)        0           convolution1d_97[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_98 (Convolution1D) (None, 13, 32)        8224        maxpooling1d_70[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_71 (MaxPooling1D)   (None, 6, 32)         0           convolution1d_98[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)             (None, 192)           0           maxpooling1d_71[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_131 (Dense)                (None, 128)           24704       flatten_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 128)           0           dense_131[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_132 (Dense)                (None, 1)             129         dropout_35[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 10054669\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 994s - loss: 0.3185 - acc: 0.8590 - val_loss: 0.2498 - val_acc: 0.8960\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1528s - loss: 0.1880 - acc: 0.9255 - val_loss: 0.2657 - val_acc: 0.8954\n",
      "Accuracy: 89.30%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 100\n",
    "filters = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution1D(filters, 2, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 4, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 5, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 8, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=32, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_34 (Embedding)         (None, 188, 50)       5002950     embedding_input_34[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 188, 50)       0           embedding_34[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_45 (Convolution1D) (None, 186, 10)       1510        dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_22 (MaxPooling1D)   (None, 93, 10)        0           convolution1d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_46 (Convolution1D) (None, 86, 10)        810         maxpooling1d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_23 (MaxPooling1D)   (None, 43, 10)        0           convolution1d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 50)            12200       maxpooling1d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_117 (Dense)                (None, 250)           12750       lstm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_118 (Dense)                (None, 250)           62750       dense_117[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_119 (Dense)                (None, 125)           31375       dense_118[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_120 (Dense)                (None, 1)             126         dense_119[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5124471\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 109660 samples, validate on 46998 samples\n",
      "Epoch 1/30\n",
      "109660/109660 [==============================] - 300s - loss: 0.3536 - acc: 0.8414 - val_loss: 0.2722 - val_acc: 0.8888\n",
      "Epoch 2/30\n",
      "109660/109660 [==============================] - 427s - loss: 0.2257 - acc: 0.9095 - val_loss: 0.2666 - val_acc: 0.8898\n",
      "Epoch 3/30\n",
      "109660/109660 [==============================] - 471s - loss: 0.1749 - acc: 0.9320 - val_loss: 0.2608 - val_acc: 0.8939\n",
      "Epoch 4/30\n",
      "109660/109660 [==============================] - 449s - loss: 0.1447 - acc: 0.9446 - val_loss: 0.3045 - val_acc: 0.8906\n",
      "Accuracy: 89.32%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059\n",
    "max_length = 188\n",
    "embedding_vector_length = 50\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "kernel_size = 3\n",
    "filters = 10\n",
    "pool_size = 2\n",
    "\n",
    "ltsm_output_size = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution1D(filters, kernel_size, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(Convolution1D(filters, 8, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=64, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_48 (Embedding)         (None, 188, 100)      10005900    embedding_input_43[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 188, 100)      0           embedding_48[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_91 (Convolution1D) (None, 187, 32)       6432        dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_64 (MaxPooling1D)   (None, 93, 32)        0           convolution1d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_92 (Convolution1D) (None, 90, 32)        4128        maxpooling1d_64[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_65 (MaxPooling1D)   (None, 45, 32)        0           convolution1d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_93 (Convolution1D) (None, 41, 32)        5152        maxpooling1d_65[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_66 (MaxPooling1D)   (None, 20, 32)        0           convolution1d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_94 (Convolution1D) (None, 13, 32)        8224        maxpooling1d_66[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_67 (MaxPooling1D)   (None, 6, 32)         0           convolution1d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 50)            16600       maxpooling1d_67[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_129 (Dense)                (None, 128)           6528        lstm_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 128)           0           dense_129[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_130 (Dense)                (None, 1)             129         dropout_33[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 10053093\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 968s - loss: 0.3339 - acc: 0.8519 - val_loss: 0.2601 - val_acc: 0.8922\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1500s - loss: 0.2085 - acc: 0.9177 - val_loss: 0.2422 - val_acc: 0.8996\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 10220s - loss: 0.1538 - acc: 0.9408 - val_loss: 0.2707 - val_acc: 0.8931\n",
      "Accuracy: 89.21%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059\n",
    "max_length = 188\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "embedding_vector_length = 100\n",
    "filters = 32\n",
    "output_size= 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Convolution1D(filters, 2, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 4, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 5, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Convolution1D(filters, 8, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=32, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_55 (Embedding)         (None, 188, 128)      12807552    embedding_input_50[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 188, 128)      0           embedding_55[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_104 (Convolution1D)(None, 184, 64)       41024       dropout_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_77 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_104[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                   (None, 70)            37800       maxpooling1d_77[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_138 (Dense)                (None, 1)             71          lstm_15[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 12886447\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 998s - loss: 0.3133 - acc: 0.8635 - val_loss: 0.2455 - val_acc: 0.9004\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1273s - loss: 0.1678 - acc: 0.9351 - val_loss: 0.2523 - val_acc: 0.9031\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 1230s - loss: 0.0876 - acc: 0.9689 - val_loss: 0.2783 - val_acc: 0.9005\n",
      "Accuracy: 90.07%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 128\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 70\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_56 (Embedding)         (None, 188, 200)      20011800    embedding_input_51[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)             (None, 188, 200)      0           embedding_56[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_105 (Convolution1D)(None, 185, 64)       51264       dropout_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_78 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_105[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                   (None, 25)            9000        maxpooling1d_78[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_139 (Dense)                (None, 250)           6500        lstm_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_140 (Dense)                (None, 250)           62750       dense_139[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_141 (Dense)                (None, 125)           31375       dense_140[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_142 (Dense)                (None, 1)             126         dense_141[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 20172815\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 1149s - loss: 0.3172 - acc: 0.8577 - val_loss: 0.2416 - val_acc: 0.8961\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1635s - loss: 0.1574 - acc: 0.9392 - val_loss: 0.2511 - val_acc: 0.9032\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 1734s - loss: 0.0770 - acc: 0.9728 - val_loss: 0.2709 - val_acc: 0.9004\n",
      "Accuracy: 89.97%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 200\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 4\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 25\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, border_mode=\"valid\", subsample_length=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_58 (Embedding)         (None, 188, 128)      12807552    embedding_input_53[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_108 (Convolution1D)(None, 185, 64)       32832       embedding_58[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_81 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_108[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                   (None, 64)            33024       maxpooling1d_81[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_147 (Dense)                (None, 64)            4160        lstm_18[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_148 (Dense)                (None, 1)             65          dense_147[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 12877633\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 1011s - loss: 0.3057 - acc: 0.8667 - val_loss: 0.2456 - val_acc: 0.8962\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 40433s - loss: 0.1414 - acc: 0.9462 - val_loss: 0.2494 - val_acc: 0.9038\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 1033s - loss: 0.0591 - acc: 0.9800 - val_loss: 0.3392 - val_acc: 0.8993\n",
      "Accuracy: 89.91%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 128\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 4\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 64\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_61 (Embedding)         (None, 188, 128)      12807552    embedding_input_56[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_112 (Convolution1D)(None, 185, 64)       32832       embedding_61[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_85 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_112[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                   (None, 46, 32)        12416       maxpooling1d_85[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                   (None, 32)            8320        lstm_22[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_151 (Dense)                (None, 32)            1056        lstm_23[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_152 (Dense)                (None, 1)             33          dense_151[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 12862209\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 761s - loss: 0.3082 - acc: 0.8643 - val_loss: 0.2494 - val_acc: 0.8955\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1036s - loss: 0.1435 - acc: 0.9452 - val_loss: 0.2565 - val_acc: 0.9019\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 1061s - loss: 0.0610 - acc: 0.9796 - val_loss: 0.3141 - val_acc: 0.8914\n",
      "Accuracy: 89.14%\n"
     ]
    }
   ],
   "source": [
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 128\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 4\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 32\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size, return_sequences=True)) \n",
    "model.add(LSTM(ltsm_output_size)) \n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_62 (Embedding)         (None, 188, 128)      12807552    embedding_input_57[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)             (None, 188, 128)      0           embedding_62[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_113 (Convolution1D)(None, 184, 64)       41024       dropout_44[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_86 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_113[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                   (None, 46, 70)        37800       maxpooling1d_86[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                   (None, 70)            39480       lstm_24[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_153 (Dense)                (None, 1)             71          lstm_25[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 12925927\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 1003s - loss: 0.3113 - acc: 0.8645 - val_loss: 0.2397 - val_acc: 0.9006\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 1301s - loss: 0.1637 - acc: 0.9370 - val_loss: 0.2733 - val_acc: 0.8928\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 1357s - loss: 0.0860 - acc: 0.9698 - val_loss: 0.3397 - val_acc: 0.8972\n",
      "Accuracy: 90.09%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 128\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 70\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size, return_sequences=True)) \n",
    "model.add(LSTM(ltsm_output_size))  \n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_65 (Embedding)         (None, 188, 256)      25615104    embedding_input_60[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 188, 256)      0           embedding_65[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_117 (Convolution1D)(None, 185, 64)       65600       dropout_47[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_90 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_117[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                   (None, 46, 32)        12416       maxpooling1d_90[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                   (None, 32)            8320        lstm_31[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_156 (Dense)                (None, 1)             33          lstm_32[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 25701473\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 4455s - loss: 0.3128 - acc: 0.8619 - val_loss: 0.2455 - val_acc: 0.8943\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 2397s - loss: 0.1553 - acc: 0.9405 - val_loss: 0.2352 - val_acc: 0.9052\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 2392s - loss: 0.0768 - acc: 0.9732 - val_loss: 0.2701 - val_acc: 0.9002\n",
      "Epoch 4/10\n",
      "125326/125326 [==============================] - 2391s - loss: 0.0412 - acc: 0.9864 - val_loss: 0.3227 - val_acc: 0.8993\n",
      "Accuracy: 89.71%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 256\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 4\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size, return_sequences=True)) \n",
    "model.add(LSTM(ltsm_output_size))  \n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_64 (Embedding)         (None, 188, 256)      25615104    embedding_input_59[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 188, 256)      0           embedding_64[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_116 (Convolution1D)(None, 184, 64)       81984       dropout_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_89 (MaxPooling1D)   (None, 46, 64)        0           convolution1d_116[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                   (None, 46, 64)        33024       maxpooling1d_89[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                   (None, 46, 64)        33024       lstm_28[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                   (None, 64)            33024       lstm_29[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_155 (Dense)                (None, 1)             65          lstm_30[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 25796225\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 1799s - loss: 0.3201 - acc: 0.8585 - val_loss: 0.2528 - val_acc: 0.8862\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 37648s - loss: 0.1670 - acc: 0.9357 - val_loss: 0.2529 - val_acc: 0.8885\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 2619s - loss: 0.0887 - acc: 0.9686 - val_loss: 0.2843 - val_acc: 0.9000\n",
      "Accuracy: 90.07%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 256\n",
    "early_stopping_monitor = EarlyStopping(patience=1)\n",
    "\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "ltsm_output_size = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(filters, kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size))\n",
    "model.add(LSTM(ltsm_output_size, return_sequences=True)) \n",
    "model.add(LSTM(ltsm_output_size, return_sequences=True)) \n",
    "model.add(LSTM(ltsm_output_size))  \n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_71 (Embedding)         (None, 188, 32)       3201888     embedding_input_66[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_124 (Convolution1D)(None, 186, 4)        388         embedding_71[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling1d_6 (AveragePoolin(None, 93, 4)         0           convolution1d_124[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 372)           0           averagepooling1d_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dense_161 (Dense)                (None, 1)             373         flatten_36[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 3202649\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 125326 samples, validate on 31332 samples\n",
      "Epoch 1/10\n",
      "125326/125326 [==============================] - 344s - loss: 0.3285 - acc: 0.8511 - val_loss: 0.2647 - val_acc: 0.8891\n",
      "Epoch 2/10\n",
      "125326/125326 [==============================] - 454s - loss: 0.2049 - acc: 0.9178 - val_loss: 0.2642 - val_acc: 0.8910\n",
      "Epoch 3/10\n",
      "125326/125326 [==============================] - 451s - loss: 0.1575 - acc: 0.9389 - val_loss: 0.2758 - val_acc: 0.8907\n",
      "Accuracy: 89.13%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import AveragePooling1D\n",
    "\n",
    "max_features = 100059 \n",
    "max_length = 188\n",
    "embedding_vector_length = 32\n",
    "early_stopping_monitor = EarlyStopping(patience=0)\n",
    "\n",
    "kernel_size = 3\n",
    "filters = 4\n",
    "pool_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vector_length, input_length = max_length))\n",
    "model.add(Convolution1D(filters, kernel_size, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size))\n",
    "model.add(Flatten())\n",
    "#372\n",
    "model.add(Dense(1, activation='sigmoid'))    \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=32, validation_split=0.2, verbose = True, callbacks=[early_stopping_monitor])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.save_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.save_weights of <keras.models.Sequential object at 0x1691b7610>>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('sentiment_model_June_19_2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jojos bizarre adventure eyes in heaven features fun combat and a crazy story youll find hard not to get sucked into\n",
      "ugh this game is not good i would not recommend it\n",
      "[18566, 14, 10, 6, 23, 55, 30, 104, 23, 322, 7]\n",
      "(188,)\n",
      "3\n",
      "[[18566    14    10     6    23    55    30   104    23   322     7     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   14     6     2    45    10    30   132     7     1   107    22    74\n",
      "     55     3     1   164     6   472  1239     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [30743  1669   151  1063     8  2550   233    49   164     3     2  1104\n",
      "     62   326   134   183    23     5    80  4333    64     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "import keras \n",
    "\n",
    "text_test = 'This is a great game! I love it. THe graphics are really good and the combat is super smooth'\n",
    "text_test2 = 'Ugh, this game is not good. I would not recommend it'\n",
    "tester = subset['textClean'][1]\n",
    "print tester\n",
    "\n",
    "cleaned = cleaning_text(text_test)\n",
    "cleaned2 = cleaning_text(text_test2)\n",
    "\n",
    "print cleaned2\n",
    "\n",
    "#create data set, both features and labels\n",
    "x = tk.texts_to_sequences([cleaned2, cleaned, tester])\n",
    "\n",
    "print x[0]\n",
    "\n",
    "x = sequence.pad_sequences(x, maxlen = max_length, padding = 'post')\n",
    "\n",
    "print x[0].shape\n",
    "\n",
    "print len(x)\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(tk, open(\"tk.pickle\", \"wb\"))\n",
    "with open('tk.pickle', 'wb') as handle:\n",
    "    pickle.dump(tk, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hmm, it seems like you didn't have a positive experience, are you sure about that score?\""
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = 'I had to wait for two hours and once I was on the phone the representative was very rude'\n",
    "rating = 8\n",
    "\n",
    "def sentiment_predictor(input_str, rating):\n",
    "    dummy = ''\n",
    "    cleaned = cleaning_text(input_str)\n",
    "    sequences = tk.texts_to_sequences([dummy, cleaned])\n",
    "    padded_sequences = sequence.pad_sequences(sequences, maxlen = 188, padding = 'post')\n",
    "    #drop_dummy = padded_sequences[1]\n",
    "    #print drop_dummy.shape\n",
    "    preds = model.predict(padded_sequences)\n",
    "\n",
    "\n",
    "    #either 0 or 1\n",
    "    \n",
    "    predicted_rating = round(preds[1])\n",
    "    print predicted_rating \n",
    "    \n",
    "    if rating <= 6 and predicted_rating == 1:\n",
    "        return 'Are you sure about that score? It seems like you had a positive experience'\n",
    "    elif rating >= 7 and predicted_rating == 0:\n",
    "        return \"It seems like you didn't have a positive experience, are you sure about that score?\"\n",
    "\n",
    "sentiment_predictor(input_str, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
